{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import ConcatDataset\nfrom PIL import Image\nimport os\nimport torchvision.models as models\nimport time\nimport copy\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport random\nfrom collections import defaultdict\nimport pandas as pd\n\nimport torch.nn.functional as F\n\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef get_indexes(arr, value):\n    indexes = []\n    for i in range(len(arr)):\n        if arr[i] == value:\n            indexes.append(i)\n    return indexes\n\ndef get_length_per_class(dataloader, classes):\n    class_counts = defaultdict(int)\n    total = 0\n    for batch in dataloader:\n        _, labels = batch \n        labels = labels.numpy().tolist()\n        for label in labels:\n            class_counts[label] += 1\n            total +=1\n\n    class_counts = dict(sorted(class_counts.items()))\n    for class_label, count in class_counts.items():\n        print(f\"Class {classes[class_label]}: {count} samples out of {total}\")\ndef load_data(data_dir,\n                           batch_size,\n                           data_type,\n                           noise_type,\n                           noise_percentage,                           \n                           transform,                           \n                           data_percentage=1,\n                           show_classes = False, random_seed=21):\n    \n    if noise_type == \"None\":\n        noise_type = \"\"\n        noise_percentage = \"\"\n    else:\n        noise_type = \"/\" + str(noise_type)\n        noise_percentage = \"/\" + str(noise_percentage)\n    path = data_dir + noise_type + \"/\" + data_type + noise_percentage\n    print(\"path: \", path)\n    dataset = ImageFolder(root=path, transform=transform)\n    original_classes = dataset.classes \n    num_samples = len(dataset)\n    indices = list(range(num_samples))\n\n    labels = dataset.targets\n    class_to_idx = dataset.class_to_idx\n    needed_length = int(num_samples*data_percentage/100)\n    expected_length_per_class = int(needed_length/len(original_classes))\n    print(f\"needed_length: {needed_length}, expected_length_per_class: {expected_length_per_class}\")\n    if data_percentage != 100:\n        new_indices = []\n        for key, value in class_to_idx.items():\n            all_indixes_of_class = get_indexes(labels, value)\n            new_indices.extend(all_indixes_of_class[:expected_length_per_class])\n    else:\n        new_indices = indices\n    length_dataset = len(new_indices)\n    print(\"length of final dataset:\", length_dataset)\n\n    \n    # sampler = SubsetRandomSampler(new_indices)\n\n    dataloader = DataLoader(dataset, sampler=new_indices, batch_size=batch_size)\n\n    if show_classes:\n        get_length_per_class(dataloader, original_classes)\n        \n    random.shuffle(new_indices)\n\n   \n    dataloader = DataLoader(dataset, sampler=new_indices, batch_size=batch_size)\n\n    return dataloader, length_dataset, original_classes\n\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25, batch_show = 1792):\n    since = time.time()\n    valid_acc = []\n    train_acc = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n\n        \n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()  \n\n            running_loss = 0.0\n            running_corrects = 0\n            l = 0\n\n            \n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.clone().detach().to(device)\n                labels = labels.clone().detach().to(device)\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    if not isinstance(outputs, torch.Tensor):\n                        outputs = outputs.logits\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                l += len(inputs)\n                \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            if phase == 'train':\n                scheduler.step()\n                train_acc.append(epoch_acc.item())\n            else:\n                valid_acc.append(epoch_acc.item())\n                \n            \n            \n            \n            print('\\n{} Loss: {:.4f} Acc: {:.4f}\\n'.format(\n                phase, epoch_loss, epoch_acc))\n\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        \n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    \n   \n\n    accuracy_history = [train_acc, valid_acc]\n    model.load_state_dict(best_model_wts)\n    return model, best_acc.item(), accuracy_history\n    \n    \n\n\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-30T18:08:42.256513Z","iopub.execute_input":"2023-07-30T18:08:42.257561Z","iopub.status.idle":"2023-07-30T18:08:49.613102Z","shell.execute_reply.started":"2023-07-30T18:08:42.257500Z","shell.execute_reply":"2023-07-30T18:08:49.612121Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4680, 0.4647, 0.3441], std=[0.2322, 0.2272, 0.2394]) \n])   \n\nnoise_type = \"gaussian_noise\"\nnoise_percentage = 10\ndata_percentage = 100\ntotal_size = 21000\n\ntrain_size = data_percentage*total_size/100\ndata_dir = '/kaggle/input/vegetableimages/vegetable_images'\n\ntrain_loader, train_size, classes = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"train\",\n                           noise_type = \"None\",\n                           noise_percentage = 0,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\n\nvalid_loader, valid_size, _ = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"validation\",\n                           noise_type = \"None\",\n                           noise_percentage = 0,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\n\nvalid_loader_with_noise, _, _ = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"validation\",\n                           noise_type = noise_type,\n                           noise_percentage = noise_percentage,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\ndataloaders = {'train':  train_loader, \n               'val': valid_loader_with_noise\n               }\ndataloaders_with_noise = {'train':  train_loader, \n               'val': valid_loader_with_noise\n               }\n\n\ntest_loader,test_size_, _ = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"test\",\n                           noise_type = \"gaussian_noise\",\n                           noise_percentage = noise_percentage,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\n\n\ntest_loader_without_noise, _, _ = load_data(data_dir =data_dir,\n                           batch_size = 64,\n                           data_type = \"test\",\n                           noise_type = \"None\",\n                           noise_percentage = 0,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\ndataset_sizes = {'train':  train_size, \n        'val': valid_size,\n        'test': test_size_\n       }\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-30T18:08:49.615482Z","iopub.execute_input":"2023-07-30T18:08:49.616511Z","iopub.status.idle":"2023-07-30T18:09:08.064652Z","shell.execute_reply.started":"2023-07-30T18:08:49.616474Z","shell.execute_reply":"2023-07-30T18:09:08.063604Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"path:  /kaggle/input/vegetableimages/vegetable_images/train\nneeded_length: 15000, expected_length_per_class: 1000\nlength of final dataset: 15000\npath:  /kaggle/input/vegetableimages/vegetable_images/validation\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\npath:  /kaggle/input/vegetableimages/vegetable_images/gaussian_noise/validation/10\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\npath:  /kaggle/input/vegetableimages/vegetable_images/gaussian_noise/test/10\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\npath:  /kaggle/input/vegetableimages/vegetable_images/test\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_vgg16():\n    vgg16 = models.vgg16(weights = True)\n    in_features = vgg16._modules['classifier'][-1].in_features\n    out_features = len(classes)\n    vgg16._modules['classifier'][-1] = nn.Linear(in_features, out_features, bias=True)\n    vgg16 = vgg16.to(device)\n    for param in vgg16.parameters():\n        param.requires_grad = True\n    return vgg16\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-30T18:09:08.066125Z","iopub.execute_input":"2023-07-30T18:09:08.067284Z","iopub.status.idle":"2023-07-30T18:09:08.074992Z","shell.execute_reply.started":"2023-07-30T18:09:08.067247Z","shell.execute_reply":"2023-07-30T18:09:08.074025Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nlearning_rates = [0.005]\nmomentums = [0, 0.1]\nsteps = [3, 4]\ngammas = [0.1,  0.5]\nc = 0\ncolumns = ['model', 'num_epochs', 'learning_rate', 'momentum', 'step', 'gamma', 'accuracy', 'history']\nnum_epochs = 10\nht_results = pd.DataFrame(columns = columns)\nbest_valid_score = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfor lr in learning_rates:\n    for m in momentums:\n        for s in steps:\n            for g in gammas: \n                c+=1\n                print(f\"STARTING {c} ITERATION\")\n                vgg16_cr = load_vgg16()\n                print(f\"Starting to test lr = {lr}, m = {m}, s = {s}, g = {g}\")\n                optimizer = optim.SGD(vgg16_cr.parameters(), lr= lr, momentum = m)\n                step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n                vgg16_cr, valid_score, history = train_model(vgg16_cr, criterion, optimizer, \n                                                      step_lr_scheduler, num_epochs=num_epochs)\n                if best_valid_score < valid_score:\n                    best_valid_score = valid_score\n                    best_vgg16 = vgg16_cr\n                ht_results.loc[len(ht_results.index)] = ['vgg16', num_epochs, lr, m, s, g, valid_score, history]                \n                print(ht_results.loc[len(ht_results.index) - 1])\n                \n        \n        \n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-30T18:09:08.076231Z","iopub.execute_input":"2023-07-30T18:09:08.076817Z","iopub.status.idle":"2023-07-31T01:01:21.009573Z","shell.execute_reply.started":"2023-07-30T18:09:08.076782Z","shell.execute_reply":"2023-07-31T01:01:21.007472Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"STARTING 1 ITERATION\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 258MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0, s = 3, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 0.2291 Acc: 0.9321\n\n\nval Loss: 0.1520 Acc: 0.9490\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0235 Acc: 0.9941\n\n\nval Loss: 0.0759 Acc: 0.9743\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0097 Acc: 0.9977\n\n\nval Loss: 0.0724 Acc: 0.9777\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0089 Acc: 0.9969\n\n\nval Loss: 0.0605 Acc: 0.9813\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0049 Acc: 0.9984\n\n\nval Loss: 0.0811 Acc: 0.9800\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0026 Acc: 0.9992\n\n\nval Loss: 0.0685 Acc: 0.9817\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0019 Acc: 0.9994\n\n\nval Loss: 0.0792 Acc: 0.9797\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0019 Acc: 0.9997\n\n\nval Loss: 0.0672 Acc: 0.9823\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0021 Acc: 0.9996\n\n\nval Loss: 0.0731 Acc: 0.9810\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0019 Acc: 0.9993\n\n\nval Loss: 0.0786 Acc: 0.9807\n\nTraining complete in 52m 7s\nBest val Acc: 0.982333\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             3\ngamma                                                          0.1\naccuracy                                                  0.982333\nhistory          [[0.9320666666666667, 0.9941333333333334, 0.99...\nName: 0, dtype: object\nSTARTING 2 ITERATION\nStarting to test lr = 0.005, m = 0, s = 3, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 0.2204 Acc: 0.9356\n\n\nval Loss: 0.0824 Acc: 0.9763\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0218 Acc: 0.9923\n\n\nval Loss: 0.0757 Acc: 0.9743\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0109 Acc: 0.9963\n\n\nval Loss: 0.0746 Acc: 0.9747\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0074 Acc: 0.9976\n\n\nval Loss: 0.0750 Acc: 0.9780\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0040 Acc: 0.9988\n\n\nval Loss: 0.0771 Acc: 0.9750\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0026 Acc: 0.9991\n\n\nval Loss: 0.0622 Acc: 0.9783\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0025 Acc: 0.9993\n\n\nval Loss: 0.0493 Acc: 0.9817\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0018 Acc: 0.9995\n\n\nval Loss: 0.0489 Acc: 0.9830\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0013 Acc: 0.9997\n\n\nval Loss: 0.0500 Acc: 0.9817\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0023 Acc: 0.9994\n\n\nval Loss: 0.0458 Acc: 0.9843\n\nTraining complete in 50m 46s\nBest val Acc: 0.984333\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             3\ngamma                                                          0.5\naccuracy                                                  0.984333\nhistory          [[0.9356000000000001, 0.9923333333333334, 0.99...\nName: 1, dtype: object\nSTARTING 3 ITERATION\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0, s = 4, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 0.2180 Acc: 0.9353\n\n\nval Loss: 0.0712 Acc: 0.9780\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0208 Acc: 0.9947\n\n\nval Loss: 0.0979 Acc: 0.9667\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0131 Acc: 0.9959\n\n\nval Loss: 0.0873 Acc: 0.9697\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0058 Acc: 0.9983\n\n\nval Loss: 0.0634 Acc: 0.9780\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0051 Acc: 0.9984\n\n\nval Loss: 0.1154 Acc: 0.9647\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0030 Acc: 0.9992\n\n\nval Loss: 0.0635 Acc: 0.9770\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0026 Acc: 0.9993\n\n\nval Loss: 0.0678 Acc: 0.9767\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0022 Acc: 0.9996\n\n\nval Loss: 0.0644 Acc: 0.9787\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0021 Acc: 0.9994\n\n\nval Loss: 0.0586 Acc: 0.9797\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0022 Acc: 0.9994\n\n\nval Loss: 0.0576 Acc: 0.9803\n\nTraining complete in 50m 8s\nBest val Acc: 0.980333\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             4\ngamma                                                          0.1\naccuracy                                                  0.980333\nhistory          [[0.9353333333333333, 0.9947333333333334, 0.99...\nName: 2, dtype: object\nSTARTING 4 ITERATION\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0, s = 4, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 0.2321 Acc: 0.9315\n\n\nval Loss: 0.0852 Acc: 0.9730\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0219 Acc: 0.9937\n\n\nval Loss: 0.1599 Acc: 0.9583\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0133 Acc: 0.9960\n\n\nval Loss: 0.0400 Acc: 0.9860\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0056 Acc: 0.9982\n\n\nval Loss: 0.0720 Acc: 0.9803\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0043 Acc: 0.9987\n\n\nval Loss: 0.0622 Acc: 0.9767\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0027 Acc: 0.9993\n\n\nval Loss: 0.0486 Acc: 0.9830\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0023 Acc: 0.9995\n\n\nval Loss: 0.0510 Acc: 0.9837\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0016 Acc: 0.9996\n\n\nval Loss: 0.0414 Acc: 0.9877\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0019 Acc: 0.9996\n\n\nval Loss: 0.0439 Acc: 0.9873\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0013 Acc: 0.9998\n\n\nval Loss: 0.0443 Acc: 0.9870\n\nTraining complete in 51m 32s\nBest val Acc: 0.987667\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             4\ngamma                                                          0.5\naccuracy                                                  0.987667\nhistory          [[0.9314666666666667, 0.9936666666666667, 0.99...\nName: 3, dtype: object\nSTARTING 5 ITERATION\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0.1, s = 3, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 0.2131 Acc: 0.9370\n\n\nval Loss: 0.0965 Acc: 0.9700\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0242 Acc: 0.9926\n\n\nval Loss: 0.0729 Acc: 0.9770\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0114 Acc: 0.9967\n\n\nval Loss: 0.0566 Acc: 0.9817\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0058 Acc: 0.9983\n\n\nval Loss: 0.0770 Acc: 0.9763\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0042 Acc: 0.9989\n\n\nval Loss: 0.0754 Acc: 0.9777\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0026 Acc: 0.9993\n\n\nval Loss: 0.0333 Acc: 0.9910\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0020 Acc: 0.9996\n\n\nval Loss: 0.0317 Acc: 0.9907\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0018 Acc: 0.9996\n\n\nval Loss: 0.0327 Acc: 0.9907\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0015 Acc: 0.9999\n\n\nval Loss: 0.0313 Acc: 0.9913\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0017 Acc: 0.9997\n\n\nval Loss: 0.0313 Acc: 0.9907\n\nTraining complete in 51m 60s\nBest val Acc: 0.991333\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             3\ngamma                                                          0.1\naccuracy                                                  0.991333\nhistory          [[0.937, 0.9926, 0.9966666666666667, 0.9983333...\nName: 4, dtype: object\nSTARTING 6 ITERATION\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0.1, s = 3, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 0.2150 Acc: 0.9371\n\n\nval Loss: 0.1048 Acc: 0.9627\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0192 Acc: 0.9945\n\n\nval Loss: 0.1531 Acc: 0.9597\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0109 Acc: 0.9971\n\n\nval Loss: 0.0456 Acc: 0.9847\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0042 Acc: 0.9987\n\n\nval Loss: 0.0376 Acc: 0.9877\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0045 Acc: 0.9989\n\n\nval Loss: 0.1058 Acc: 0.9700\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0024 Acc: 0.9993\n\n\nval Loss: 0.0500 Acc: 0.9857\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0018 Acc: 0.9994\n\n\nval Loss: 0.0449 Acc: 0.9870\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0021 Acc: 0.9995\n\n\nval Loss: 0.0460 Acc: 0.9863\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0015 Acc: 0.9998\n\n\nval Loss: 0.0493 Acc: 0.9857\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0020 Acc: 0.9992\n\n\nval Loss: 0.0486 Acc: 0.9860\n\nTraining complete in 51m 9s\nBest val Acc: 0.987667\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             3\ngamma                                                          0.5\naccuracy                                                  0.987667\nhistory          [[0.9370666666666667, 0.9944666666666667, 0.99...\nName: 5, dtype: object\nSTARTING 7 ITERATION\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0.1, s = 4, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 0.2074 Acc: 0.9378\n\n\nval Loss: 0.1422 Acc: 0.9540\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0243 Acc: 0.9931\n\n\nval Loss: 0.0492 Acc: 0.9827\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0097 Acc: 0.9972\n\n\nval Loss: 0.0541 Acc: 0.9807\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0077 Acc: 0.9978\n\n\nval Loss: 0.0502 Acc: 0.9830\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0057 Acc: 0.9983\n\n\nval Loss: 0.0619 Acc: 0.9800\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0032 Acc: 0.9992\n\n\nval Loss: 0.0389 Acc: 0.9873\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0024 Acc: 0.9993\n\n\nval Loss: 0.0334 Acc: 0.9900\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0020 Acc: 0.9995\n\n\nval Loss: 0.0336 Acc: 0.9900\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0018 Acc: 0.9995\n\n\nval Loss: 0.0332 Acc: 0.9897\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0013 Acc: 0.9997\n\n\nval Loss: 0.0368 Acc: 0.9893\n\nTraining complete in 52m 2s\nBest val Acc: 0.990000\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             4\ngamma                                                          0.1\naccuracy                                                      0.99\nhistory          [[0.9378000000000001, 0.9931333333333334, 0.99...\nName: 6, dtype: object\nSTARTING 8 ITERATION\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0.1, s = 4, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 0.2109 Acc: 0.9381\n\n\nval Loss: 0.0955 Acc: 0.9653\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.0195 Acc: 0.9944\n\n\nval Loss: 0.1050 Acc: 0.9653\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0123 Acc: 0.9959\n\n\nval Loss: 0.0712 Acc: 0.9770\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0071 Acc: 0.9979\n\n\nval Loss: 0.0369 Acc: 0.9870\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0032 Acc: 0.9990\n\n\nval Loss: 0.0823 Acc: 0.9730\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0021 Acc: 0.9995\n\n\nval Loss: 0.0703 Acc: 0.9757\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0019 Acc: 0.9994\n\n\nval Loss: 0.0672 Acc: 0.9767\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0012 Acc: 0.9998\n\n\nval Loss: 0.0659 Acc: 0.9767\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0015 Acc: 0.9995\n\n\nval Loss: 0.0666 Acc: 0.9777\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0013 Acc: 0.9997\n\n\nval Loss: 0.0644 Acc: 0.9780\n\nTraining complete in 52m 7s\nBest val Acc: 0.987000\nmodel                                                        vgg16\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             4\ngamma                                                          0.5\naccuracy                                                     0.987\nhistory          [[0.9380666666666667, 0.9944000000000001, 0.99...\nName: 7, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"ht_results.to_csv('vgg16_results.csv', index=False)\ntorch.save(best_vgg16, \"best_vgg16.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-07-31T01:01:21.012782Z","iopub.execute_input":"2023-07-31T01:01:21.013082Z","iopub.status.idle":"2023-07-31T01:01:22.066669Z","shell.execute_reply.started":"2023-07-31T01:01:21.013056Z","shell.execute_reply":"2023-07-31T01:01:22.065683Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working\n\nfrom IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T01:01:22.068318Z","iopub.execute_input":"2023-07-31T01:01:22.068738Z","iopub.status.idle":"2023-07-31T01:01:53.174195Z","shell.execute_reply.started":"2023-07-31T01:01:22.068680Z","shell.execute_reply":"2023-07-31T01:01:53.172955Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/vgg16_results.csv (deflated 82%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/best_vgg16.pth (deflated 7%)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
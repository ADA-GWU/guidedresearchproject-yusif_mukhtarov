{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-30T20:13:05.011449Z","iopub.status.busy":"2023-07-30T20:13:05.011045Z","iopub.status.idle":"2023-07-30T20:13:10.368327Z","shell.execute_reply":"2023-07-30T20:13:10.366009Z","shell.execute_reply.started":"2023-07-30T20:13:05.011415Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ready\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import matplotlib.pyplot as plt\n","from torch.utils.data import ConcatDataset\n","from PIL import Image\n","import os\n","import torchvision.models as models\n","import time\n","import copy\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","import random\n","from collections import defaultdict\n","import pandas as pd\n","\n","import torch.nn.functional as F\n","\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def get_indexes(arr, value):\n","    indexes = []\n","    for i in range(len(arr)):\n","        if arr[i] == value:\n","            indexes.append(i)\n","    return indexes\n","\n","def get_length_per_class(dataloader, classes):\n","    class_counts = defaultdict(int)\n","    total = 0\n","    for batch in dataloader:\n","        _, labels = batch \n","        labels = labels.numpy().tolist()\n","        for label in labels:\n","            class_counts[label] += 1\n","            total +=1\n","\n","    class_counts = dict(sorted(class_counts.items()))\n","    for class_label, count in class_counts.items():\n","        print(f\"Class {classes[class_label]}: {count} samples out of {total}\")\n","def load_data(data_dir,\n","                           batch_size,\n","                           data_type,\n","                           noise_type,\n","                           noise_percentage,                           \n","                           transform,                           \n","                           data_percentage=1,\n","                           show_classes = False, random_seed=21):\n","    \n","    if noise_type == \"None\":\n","        noise_type = \"\"\n","        noise_percentage = \"\"\n","    else:\n","        noise_type = \"/\" + str(noise_type)\n","        noise_percentage = \"/\" + str(noise_percentage)\n","    path = data_dir + noise_type + \"/\" + data_type + noise_percentage\n","    print(\"path: \", path)\n","    dataset = ImageFolder(root=path, transform=transform)\n","    original_classes = dataset.classes \n","    num_samples = len(dataset)\n","    indices = list(range(num_samples))\n","\n","    labels = dataset.targets\n","    class_to_idx = dataset.class_to_idx\n","    needed_length = int(num_samples*data_percentage/100)\n","    expected_length_per_class = int(needed_length/len(original_classes))\n","    print(f\"needed_length: {needed_length}, expected_length_per_class: {expected_length_per_class}\")\n","    if data_percentage != 100:\n","        new_indices = []\n","        for key, value in class_to_idx.items():\n","            all_indixes_of_class = get_indexes(labels, value)\n","            new_indices.extend(all_indixes_of_class[:expected_length_per_class])\n","    else:\n","        new_indices = indices\n","    length_dataset = len(new_indices)\n","    print(\"length of final dataset:\", length_dataset)\n","\n","    \n","    # sampler = SubsetRandomSampler(new_indices)\n","\n","    dataloader = DataLoader(dataset, sampler=new_indices, batch_size=batch_size)\n","\n","    if show_classes:\n","        get_length_per_class(dataloader, original_classes)\n","        \n","    random.shuffle(new_indices)\n","\n","   \n","    dataloader = DataLoader(dataset, sampler=new_indices, batch_size=batch_size)\n","\n","    return dataloader, length_dataset, original_classes\n","\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25, batch_show = 1792):\n","    since = time.time()\n","    valid_acc = []\n","    train_acc = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n","        print('-' * 10)\n","\n","        \n","        \n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()  \n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            l = 0\n","\n","            \n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.clone().detach().to(device)\n","                labels = labels.clone().detach().to(device)\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    if not isinstance(outputs, torch.Tensor):\n","                        outputs = outputs.logits\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        optimizer.zero_grad()\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                l += len(inputs)\n","                \n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                \n","                \n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","            if phase == 'train':\n","                scheduler.step()\n","                train_acc.append(epoch_acc.item())\n","            else:\n","                valid_acc.append(epoch_acc.item())\n","                \n","            \n","            \n","            \n","            print('\\n{} Loss: {:.4f} Acc: {:.4f}\\n'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            \n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        \n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","    \n","    \n","   \n","\n","    accuracy_history = [train_acc, valid_acc]\n","    model.load_state_dict(best_model_wts)\n","    return model, best_acc.item(), accuracy_history\n","    \n","    \n","\n","\n","\n","\n","\n","print('ready')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T20:13:10.377944Z","iopub.status.busy":"2023-07-30T20:13:10.376128Z","iopub.status.idle":"2023-07-30T20:13:14.256056Z","shell.execute_reply":"2023-07-30T20:13:14.254934Z","shell.execute_reply.started":"2023-07-30T20:13:10.377897Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["path:  /kaggle/input/vegetableimages1/vegetable_images/train\n","needed_length: 15000, expected_length_per_class: 1000\n","length of final dataset: 15000\n","path:  /kaggle/input/vegetableimages1/vegetable_images/validation\n","needed_length: 3000, expected_length_per_class: 200\n","length of final dataset: 3000\n","path:  /kaggle/input/vegetableimages1/vegetable_images/gaussian_noise/validation/10\n","needed_length: 3000, expected_length_per_class: 200\n","length of final dataset: 3000\n","path:  /kaggle/input/vegetableimages1/vegetable_images/gaussian_noise/test/10\n","needed_length: 3000, expected_length_per_class: 200\n","length of final dataset: 3000\n","path:  /kaggle/input/vegetableimages1/vegetable_images/test\n","needed_length: 3000, expected_length_per_class: 200\n","length of final dataset: 3000\n"]}],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  \n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.4680, 0.4647, 0.3441], std=[0.2322, 0.2272, 0.2394]) \n","])   \n","\n","noise_type = \"gaussian_noise\"\n","noise_percentage = 10\n","data_percentage = 100\n","total_size = 21000\n","\n","train_size = data_percentage*total_size/100\n","data_dir = '/kaggle/input/vegetableimages1/vegetable_images'\n","\n","train_loader, train_size, classes = load_data(data_dir = data_dir,\n","                           batch_size = 64,\n","                           data_type = \"train\",\n","                           noise_type = \"None\",\n","                           noise_percentage = 0,                           \n","                           transform = transform,                           \n","                           data_percentage=data_percentage)\n","\n","valid_loader, valid_size, _ = load_data(data_dir = data_dir,\n","                           batch_size = 64,\n","                           data_type = \"validation\",\n","                           noise_type = \"None\",\n","                           noise_percentage = 0,                           \n","                           transform = transform,                           \n","                           data_percentage=data_percentage)\n","\n","valid_loader_with_noise, _, _ = load_data(data_dir = data_dir,\n","                           batch_size = 64,\n","                           data_type = \"validation\",\n","                           noise_type = noise_type,\n","                           noise_percentage = noise_percentage,                           \n","                           transform = transform,                           \n","                           data_percentage=data_percentage)\n","dataloaders = {'train':  train_loader, \n","               'val': valid_loader_with_noise\n","               }\n","dataloaders_with_noise = {'train':  train_loader, \n","               'val': valid_loader_with_noise\n","               }\n","\n","\n","test_loader,test_size_, _ = load_data(data_dir = data_dir,\n","                           batch_size = 64,\n","                           data_type = \"test\",\n","                           noise_type = \"gaussian_noise\",\n","                           noise_percentage = noise_percentage,                           \n","                           transform = transform,                           \n","                           data_percentage=data_percentage)\n","\n","\n","test_loader_without_noise, _, _ = load_data(data_dir =data_dir,\n","                           batch_size = 64,\n","                           data_type = \"test\",\n","                           noise_type = \"None\",\n","                           noise_percentage = 0,                           \n","                           transform = transform,                           \n","                           data_percentage=data_percentage)\n","dataset_sizes = {'train':  train_size, \n","        'val': valid_size,\n","        'test': test_size_\n","       }\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T20:13:14.258694Z","iopub.status.busy":"2023-07-30T20:13:14.257566Z","iopub.status.idle":"2023-07-30T20:13:14.267533Z","shell.execute_reply":"2023-07-30T20:13:14.266222Z","shell.execute_reply.started":"2023-07-30T20:13:14.258657Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'train': 15000, 'val': 3000, 'test': 3000}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset_sizes"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T20:13:14.271511Z","iopub.status.busy":"2023-07-30T20:13:14.270670Z","iopub.status.idle":"2023-07-30T20:13:14.279240Z","shell.execute_reply":"2023-07-30T20:13:14.278221Z","shell.execute_reply.started":"2023-07-30T20:13:14.271476Z"},"trusted":true},"outputs":[],"source":["def load_efficientnet():\n","    efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n","    in_features = efficientnet._modules['classifier'][-1].in_features\n","    out_features = len(classes)\n","    efficientnet._modules['classifier'][-1] = nn.Linear(in_features, out_features, bias=True)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    efficientnet = efficientnet.to(device)\n","    for param in efficientnet.parameters():\n","        param.requires_grad = True\n","    return efficientnet\n","    \n","    \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameter tuning "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T20:13:14.281629Z","iopub.status.busy":"2023-07-30T20:13:14.280901Z","iopub.status.idle":"2023-07-30T23:11:41.067003Z","shell.execute_reply":"2023-07-30T23:11:41.065751Z","shell.execute_reply.started":"2023-07-30T20:13:14.281590Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["STARTING 1 ITERATION\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n","  warnings.warn(\n","Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n","/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n","  warnings.warn(\n","/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n","  warnings.warn(\n","Downloading: \"https://api.ngc.nvidia.com/v2/models/nvidia/efficientnet_b0_pyt_amp/versions/20.12.0/files/nvidia_efficientnet-b0_210412.pth\" to /root/.cache/torch/hub/checkpoints/nvidia_efficientnet-b0_210412.pth\n","100%|██████████| 20.5M/20.5M [00:00<00:00, 24.3MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Starting to test lr = 0.005, m = 0, s = 3, g = 0.1\n","Epoch 1/10\n","----------\n","\n","train Loss: 2.0560 Acc: 0.6849\n","\n","\n","val Loss: 1.4150 Acc: 0.9247\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.8940 Acc: 0.9495\n","\n","\n","val Loss: 0.6102 Acc: 0.9617\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.3937 Acc: 0.9708\n","\n","\n","val Loss: 0.3465 Acc: 0.9737\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.2240 Acc: 0.9803\n","\n","\n","val Loss: 0.2385 Acc: 0.9817\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1503 Acc: 0.9873\n","\n","\n","val Loss: 0.1815 Acc: 0.9870\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1235 Acc: 0.9901\n","\n","\n","val Loss: 0.1803 Acc: 0.9870\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1197 Acc: 0.9903\n","\n","\n","val Loss: 0.1763 Acc: 0.9870\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.1166 Acc: 0.9905\n","\n","\n","val Loss: 0.1722 Acc: 0.9873\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.1132 Acc: 0.9901\n","\n","\n","val Loss: 0.1683 Acc: 0.9867\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.1101 Acc: 0.9911\n","\n","\n","val Loss: 0.1646 Acc: 0.9867\n","\n","Training complete in 22m 55s\n","Best val Acc: 0.987333\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                         0\n","step                                                             3\n","gamma                                                          0.1\n","accuracy                                                  0.987333\n","history          [[0.6849333333333334, 0.9494666666666667, 0.97...\n","Name: 0, dtype: object\n","STARTING 2 ITERATION\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"name":"stdout","output_type":"stream","text":["Starting to test lr = 0.005, m = 0, s = 3, g = 0.5\n","Epoch 1/10\n","----------\n","\n","train Loss: 2.0518 Acc: 0.6863\n","\n","\n","val Loss: 1.4154 Acc: 0.9193\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.8980 Acc: 0.9455\n","\n","\n","val Loss: 0.6004 Acc: 0.9540\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.4017 Acc: 0.9698\n","\n","\n","val Loss: 0.3386 Acc: 0.9713\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.2280 Acc: 0.9815\n","\n","\n","val Loss: 0.2316 Acc: 0.9800\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1516 Acc: 0.9879\n","\n","\n","val Loss: 0.1751 Acc: 0.9837\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1239 Acc: 0.9905\n","\n","\n","val Loss: 0.1741 Acc: 0.9840\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1205 Acc: 0.9906\n","\n","\n","val Loss: 0.1702 Acc: 0.9843\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.1170 Acc: 0.9913\n","\n","\n","val Loss: 0.1661 Acc: 0.9847\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.1128 Acc: 0.9917\n","\n","\n","val Loss: 0.1623 Acc: 0.9850\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.1101 Acc: 0.9909\n","\n","\n","val Loss: 0.1586 Acc: 0.9853\n","\n","Training complete in 22m 29s\n","Best val Acc: 0.985333\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                         0\n","step                                                             3\n","gamma                                                          0.5\n","accuracy                                                  0.985333\n","history          [[0.6863333333333334, 0.9455333333333333, 0.96...\n","Name: 1, dtype: object\n","STARTING 3 ITERATION\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"name":"stdout","output_type":"stream","text":["Starting to test lr = 0.005, m = 0, s = 4, g = 0.1\n","Epoch 1/10\n","----------\n","\n","train Loss: 2.0428 Acc: 0.6852\n","\n","\n","val Loss: 1.4016 Acc: 0.9317\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.8870 Acc: 0.9487\n","\n","\n","val Loss: 0.6023 Acc: 0.9633\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.3954 Acc: 0.9731\n","\n","\n","val Loss: 0.3422 Acc: 0.9720\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.2255 Acc: 0.9821\n","\n","\n","val Loss: 0.2348 Acc: 0.9793\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1502 Acc: 0.9881\n","\n","\n","val Loss: 0.1779 Acc: 0.9830\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1229 Acc: 0.9905\n","\n","\n","val Loss: 0.1768 Acc: 0.9837\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1193 Acc: 0.9905\n","\n","\n","val Loss: 0.1729 Acc: 0.9837\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.1159 Acc: 0.9899\n","\n","\n","val Loss: 0.1689 Acc: 0.9837\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.1128 Acc: 0.9907\n","\n","\n","val Loss: 0.1651 Acc: 0.9837\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.1097 Acc: 0.9909\n","\n","\n","val Loss: 0.1615 Acc: 0.9847\n","\n","Training complete in 22m 10s\n","Best val Acc: 0.984667\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                         0\n","step                                                             4\n","gamma                                                          0.1\n","accuracy                                                  0.984667\n","history          [[0.6852, 0.9487333333333334, 0.97313333333333...\n","Name: 2, dtype: object\n","STARTING 4 ITERATION\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"name":"stdout","output_type":"stream","text":["Starting to test lr = 0.005, m = 0, s = 4, g = 0.5\n","Epoch 1/10\n","----------\n","\n","train Loss: 2.0683 Acc: 0.6784\n","\n","\n","val Loss: 1.4445 Acc: 0.9210\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.9074 Acc: 0.9461\n","\n","\n","val Loss: 0.6152 Acc: 0.9563\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.4025 Acc: 0.9696\n","\n","\n","val Loss: 0.3468 Acc: 0.9700\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.2287 Acc: 0.9799\n","\n","\n","val Loss: 0.2368 Acc: 0.9800\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1517 Acc: 0.9875\n","\n","\n","val Loss: 0.1786 Acc: 0.9830\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1251 Acc: 0.9902\n","\n","\n","val Loss: 0.1769 Acc: 0.9837\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1210 Acc: 0.9900\n","\n","\n","val Loss: 0.1728 Acc: 0.9840\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.1172 Acc: 0.9907\n","\n","\n","val Loss: 0.1687 Acc: 0.9847\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.1146 Acc: 0.9905\n","\n","\n","val Loss: 0.1648 Acc: 0.9850\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.1105 Acc: 0.9909\n","\n","\n","val Loss: 0.1610 Acc: 0.9857\n","\n","Training complete in 22m 12s\n","Best val Acc: 0.985667\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                         0\n","step                                                             4\n","gamma                                                          0.5\n","accuracy                                                  0.985667\n","history          [[0.6784, 0.9461333333333334, 0.9696, 0.979933...\n","Name: 3, dtype: object\n","STARTING 5 ITERATION\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"name":"stdout","output_type":"stream","text":["Starting to test lr = 0.005, m = 0.1, s = 3, g = 0.1\n","Epoch 1/10\n","----------\n","\n","train Loss: 1.9668 Acc: 0.7213\n","\n","\n","val Loss: 1.2671 Acc: 0.9350\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.7748 Acc: 0.9549\n","\n","\n","val Loss: 0.5172 Acc: 0.9633\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.3352 Acc: 0.9747\n","\n","\n","val Loss: 0.2980 Acc: 0.9763\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.1909 Acc: 0.9843\n","\n","\n","val Loss: 0.2058 Acc: 0.9840\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1278 Acc: 0.9903\n","\n","\n","val Loss: 0.1569 Acc: 0.9867\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1043 Acc: 0.9917\n","\n","\n","val Loss: 0.1559 Acc: 0.9867\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1013 Acc: 0.9925\n","\n","\n","val Loss: 0.1524 Acc: 0.9873\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.0992 Acc: 0.9922\n","\n","\n","val Loss: 0.1488 Acc: 0.9873\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.0958 Acc: 0.9925\n","\n","\n","val Loss: 0.1453 Acc: 0.9877\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.0932 Acc: 0.9931\n","\n","\n","val Loss: 0.1421 Acc: 0.9880\n","\n","Training complete in 22m 8s\n","Best val Acc: 0.988000\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                       0.1\n","step                                                             3\n","gamma                                                          0.1\n","accuracy                                                     0.988\n","history          [[0.7212666666666667, 0.9549333333333334, 0.97...\n","Name: 4, dtype: object\n","STARTING 6 ITERATION\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"name":"stdout","output_type":"stream","text":["Starting to test lr = 0.005, m = 0.1, s = 3, g = 0.5\n","Epoch 1/10\n","----------\n","\n","train Loss: 1.9809 Acc: 0.7211\n","\n","\n","val Loss: 1.2940 Acc: 0.9443\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.7839 Acc: 0.9549\n","\n","\n","val Loss: 0.5275 Acc: 0.9630\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.3386 Acc: 0.9735\n","\n","\n","val Loss: 0.3060 Acc: 0.9727\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.1927 Acc: 0.9846\n","\n","\n","val Loss: 0.2138 Acc: 0.9810\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1293 Acc: 0.9898\n","\n","\n","val Loss: 0.1639 Acc: 0.9827\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1060 Acc: 0.9914\n","\n","\n","val Loss: 0.1628 Acc: 0.9827\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1022 Acc: 0.9921\n","\n","\n","val Loss: 0.1593 Acc: 0.9830\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.0996 Acc: 0.9923\n","\n","\n","val Loss: 0.1557 Acc: 0.9837\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.0969 Acc: 0.9923\n","\n","\n","val Loss: 0.1523 Acc: 0.9837\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.0945 Acc: 0.9925\n","\n","\n","val Loss: 0.1490 Acc: 0.9837\n","\n","Training complete in 22m 1s\n","Best val Acc: 0.983667\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                       0.1\n","step                                                             3\n","gamma                                                          0.5\n","accuracy                                                  0.983667\n","history          [[0.7210666666666667, 0.9549333333333334, 0.97...\n","Name: 5, dtype: object\n","STARTING 7 ITERATION\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"name":"stdout","output_type":"stream","text":["Starting to test lr = 0.005, m = 0.1, s = 4, g = 0.1\n","Epoch 1/10\n","----------\n","\n","train Loss: 1.9861 Acc: 0.7102\n","\n","\n","val Loss: 1.2871 Acc: 0.9313\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.7803 Acc: 0.9525\n","\n","\n","val Loss: 0.5227 Acc: 0.9627\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.3362 Acc: 0.9751\n","\n","\n","val Loss: 0.2991 Acc: 0.9737\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.1918 Acc: 0.9840\n","\n","\n","val Loss: 0.2072 Acc: 0.9803\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1282 Acc: 0.9893\n","\n","\n","val Loss: 0.1578 Acc: 0.9850\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1057 Acc: 0.9915\n","\n","\n","val Loss: 0.1562 Acc: 0.9853\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1029 Acc: 0.9915\n","\n","\n","val Loss: 0.1528 Acc: 0.9860\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.0998 Acc: 0.9920\n","\n","\n","val Loss: 0.1493 Acc: 0.9867\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.0968 Acc: 0.9921\n","\n","\n","val Loss: 0.1460 Acc: 0.9873\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.0944 Acc: 0.9924\n","\n","\n","val Loss: 0.1428 Acc: 0.9873\n","\n","Training complete in 22m 6s\n","Best val Acc: 0.987333\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                       0.1\n","step                                                             4\n","gamma                                                          0.1\n","accuracy                                                  0.987333\n","history          [[0.7102, 0.9525333333333333, 0.97506666666666...\n","Name: 6, dtype: object\n","STARTING 8 ITERATION\n","Starting to test lr = 0.005, m = 0.1, s = 4, g = 0.5\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","----------\n","\n","train Loss: 1.9767 Acc: 0.7253\n","\n","\n","val Loss: 1.2749 Acc: 0.9353\n","\n","Epoch 2/10\n","----------\n","\n","train Loss: 0.7686 Acc: 0.9558\n","\n","\n","val Loss: 0.5124 Acc: 0.9637\n","\n","Epoch 3/10\n","----------\n","\n","train Loss: 0.3300 Acc: 0.9749\n","\n","\n","val Loss: 0.2959 Acc: 0.9737\n","\n","Epoch 4/10\n","----------\n","\n","train Loss: 0.1894 Acc: 0.9839\n","\n","\n","val Loss: 0.2063 Acc: 0.9833\n","\n","Epoch 5/10\n","----------\n","\n","train Loss: 0.1274 Acc: 0.9897\n","\n","\n","val Loss: 0.1579 Acc: 0.9850\n","\n","Epoch 6/10\n","----------\n","\n","train Loss: 0.1045 Acc: 0.9909\n","\n","\n","val Loss: 0.1569 Acc: 0.9857\n","\n","Epoch 7/10\n","----------\n","\n","train Loss: 0.1016 Acc: 0.9921\n","\n","\n","val Loss: 0.1535 Acc: 0.9860\n","\n","Epoch 8/10\n","----------\n","\n","train Loss: 0.0985 Acc: 0.9921\n","\n","\n","val Loss: 0.1501 Acc: 0.9860\n","\n","Epoch 9/10\n","----------\n","\n","train Loss: 0.0961 Acc: 0.9921\n","\n","\n","val Loss: 0.1468 Acc: 0.9863\n","\n","Epoch 10/10\n","----------\n","\n","train Loss: 0.0935 Acc: 0.9931\n","\n","\n","val Loss: 0.1436 Acc: 0.9863\n","\n","Training complete in 22m 11s\n","Best val Acc: 0.986333\n","model                                                 efficientnet\n","num_epochs                                                      10\n","learning_rate                                                0.005\n","momentum                                                       0.1\n","step                                                             4\n","gamma                                                          0.5\n","accuracy                                                  0.986333\n","history          [[0.7252666666666667, 0.9558000000000001, 0.97...\n","Name: 7, dtype: object\n"]}],"source":["criterion = nn.CrossEntropyLoss()\n","learning_rates = [0.005]\n","momentums = [0, 0.1]\n","steps = [3, 4]\n","gammas = [0.1,  0.5]\n","c = 0\n","columns = ['model', 'num_epochs', 'learning_rate', 'momentum', 'step', 'gamma', 'accuracy', 'history']\n","num_epochs = 10\n","ht_results = pd.DataFrame(columns = columns)\n","best_valid_score = 0\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","for lr in learning_rates:\n","    for m in momentums:\n","        for s in steps:\n","            for g in gammas: \n","                c+=1\n","                print(f\"STARTING {c} ITERATION\")\n","                efficientnet_cr = load_efficientnet()\n","                print(f\"Starting to test lr = {lr}, m = {m}, s = {s}, g = {g}\")\n","                optimizer = optim.SGD(efficientnet_cr.parameters(), lr= lr, momentum = m)\n","                step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","                efficientnet_cr, valid_score, history = train_model(efficientnet_cr, criterion, optimizer, \n","                                                      step_lr_scheduler, num_epochs=num_epochs)\n","                if best_valid_score < valid_score:\n","                    best_valid_score = valid_score\n","                    best_efficientnet = efficientnet_cr\n","                ht_results.loc[len(ht_results.index)] = ['efficientnet', num_epochs, lr, m, s, g, valid_score, history]                \n","                print(ht_results.loc[len(ht_results.index) - 1])\n","                \n","        \n","        \n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T23:11:41.069526Z","iopub.status.busy":"2023-07-30T23:11:41.068821Z","iopub.status.idle":"2023-07-30T23:11:41.086251Z","shell.execute_reply":"2023-07-30T23:11:41.085043Z","shell.execute_reply.started":"2023-07-30T23:11:41.069485Z"},"trusted":true},"outputs":[],"source":["ht_results.to_csv('efficientnet_results.csv', index=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T23:11:41.088752Z","iopub.status.busy":"2023-07-30T23:11:41.088082Z","iopub.status.idle":"2023-07-30T23:11:41.186679Z","shell.execute_reply":"2023-07-30T23:11:41.185586Z","shell.execute_reply.started":"2023-07-30T23:11:41.088714Z"},"trusted":true},"outputs":[],"source":["torch.save(best_efficientnet, \"best_efficientnet.pth\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T23:27:54.204762Z","iopub.status.busy":"2023-07-30T23:27:54.204233Z","iopub.status.idle":"2023-07-30T23:27:56.244566Z","shell.execute_reply":"2023-07-30T23:27:56.243316Z","shell.execute_reply.started":"2023-07-30T23:27:54.204708Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/ (stored 0%)\n","  adding: kaggle/working/efficientnet_results.csv (deflated 82%)\n","  adding: kaggle/working/best_efficientnet.pth (deflated 8%)\n","  adding: kaggle/working/.virtual_documents/ (stored 0%)\n"]}],"source":["!zip -r file.zip /kaggle/working"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T23:27:56.247811Z","iopub.status.busy":"2023-07-30T23:27:56.247388Z","iopub.status.idle":"2023-07-30T23:27:57.412096Z","shell.execute_reply":"2023-07-30T23:27:57.410787Z","shell.execute_reply.started":"2023-07-30T23:27:56.247770Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["best_efficientnet.pth  efficientnet_results.csv  file.zip\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T23:27:58.607794Z","iopub.status.busy":"2023-07-30T23:27:58.607366Z","iopub.status.idle":"2023-07-30T23:27:58.617387Z","shell.execute_reply":"2023-07-30T23:27:58.616342Z","shell.execute_reply.started":"2023-07-30T23:27:58.607755Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='file.zip' target='_blank'>file.zip</a><br>"],"text/plain":["/kaggle/working/file.zip"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink\n","FileLink(r'file.zip')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T23:28:34.904254Z","iopub.status.busy":"2023-07-30T23:28:34.903839Z","iopub.status.idle":"2023-07-30T23:28:34.911350Z","shell.execute_reply":"2023-07-30T23:28:34.910228Z","shell.execute_reply.started":"2023-07-30T23:28:34.904213Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.988"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["best_valid_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import ConcatDataset\nfrom PIL import Image\nimport os\nimport torchvision.models as models\nimport time\nimport copy\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport random\nfrom collections import defaultdict\nimport pandas as pd\n\nimport torch.nn.functional as F\n\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef get_indexes(arr, value):\n    indexes = []\n    for i in range(len(arr)):\n        if arr[i] == value:\n            indexes.append(i)\n    return indexes\n\ndef get_length_per_class(dataloader, classes):\n    class_counts = defaultdict(int)\n    total = 0\n    for batch in dataloader:\n        _, labels = batch \n        labels = labels.numpy().tolist()\n        for label in labels:\n            class_counts[label] += 1\n            total +=1\n\n    class_counts = dict(sorted(class_counts.items()))\n    for class_label, count in class_counts.items():\n        print(f\"Class {classes[class_label]}: {count} samples out of {total}\")\ndef load_data(data_dir,\n                           batch_size,\n                           data_type,\n                           noise_type,\n                           noise_percentage,                           \n                           transform,                           \n                           data_percentage=1,\n                           show_classes = False, random_seed=21):\n    \n    if noise_type == \"None\":\n        noise_type = \"\"\n        noise_percentage = \"\"\n    else:\n        noise_type = \"/\" + str(noise_type)\n        noise_percentage = \"/\" + str(noise_percentage)\n    path = data_dir + noise_type + \"/\" + data_type + noise_percentage\n    print(\"path: \", path)\n    dataset = ImageFolder(root=path, transform=transform)\n    original_classes = dataset.classes \n    num_samples = len(dataset)\n    indices = list(range(num_samples))\n\n    labels = dataset.targets\n    class_to_idx = dataset.class_to_idx\n    needed_length = int(num_samples*data_percentage/100)\n    expected_length_per_class = int(needed_length/len(original_classes))\n    print(f\"needed_length: {needed_length}, expected_length_per_class: {expected_length_per_class}\")\n    if data_percentage != 100:\n        new_indices = []\n        for key, value in class_to_idx.items():\n            all_indixes_of_class = get_indexes(labels, value)\n            new_indices.extend(all_indixes_of_class[:expected_length_per_class])\n    else:\n        new_indices = indices\n    length_dataset = len(new_indices)\n    print(\"length of final dataset:\", length_dataset)\n\n    \n    # sampler = SubsetRandomSampler(new_indices)\n\n    dataloader = DataLoader(dataset, sampler=new_indices, batch_size=batch_size)\n\n    if show_classes:\n        get_length_per_class(dataloader, original_classes)\n        \n    random.shuffle(new_indices)\n\n   \n    dataloader = DataLoader(dataset, sampler=new_indices, batch_size=batch_size)\n\n    return dataloader, length_dataset, original_classes\n\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25, batch_show = 1792):\n    since = time.time()\n    valid_acc = []\n    train_acc = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n\n        \n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()  \n\n            running_loss = 0.0\n            running_corrects = 0\n            l = 0\n\n            \n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.clone().detach().to(device)\n                labels = labels.clone().detach().to(device)\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    if not isinstance(outputs, torch.Tensor):\n                        outputs = outputs.logits\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                l += len(inputs)\n                \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            if phase == 'train':\n                scheduler.step()\n                train_acc.append(epoch_acc.item())\n            else:\n                valid_acc.append(epoch_acc.item())\n                \n            \n            \n            \n            print('\\n{} Loss: {:.4f} Acc: {:.4f}\\n'.format(\n                phase, epoch_loss, epoch_acc))\n\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        \n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    \n   \n\n    accuracy_history = [train_acc, valid_acc]\n    model.load_state_dict(best_model_wts)\n    return model, best_acc.item(), accuracy_history\n    \n    \n\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-30T16:41:15.284867Z","iopub.execute_input":"2023-07-30T16:41:15.285240Z","iopub.status.idle":"2023-07-30T16:41:15.315992Z","shell.execute_reply.started":"2023-07-30T16:41:15.285207Z","shell.execute_reply":"2023-07-30T16:41:15.315048Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4680, 0.4647, 0.3441], std=[0.2322, 0.2272, 0.2394]) \n])   \n\nnoise_type = \"gaussian_noise\"\nnoise_percentage = 10\ndata_percentage = 100\ntotal_size = 21000\n\ntrain_size = data_percentage*total_size/100\ndata_dir = '/kaggle/input/vegetableimages/vegetable_images'\n\ntrain_loader, train_size, classes = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"train\",\n                           noise_type = \"None\",\n                           noise_percentage = 0,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\n\nvalid_loader, valid_size, _ = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"validation\",\n                           noise_type = \"None\",\n                           noise_percentage = 0,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\n\nvalid_loader_with_noise, _, _ = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"validation\",\n                           noise_type = noise_type,\n                           noise_percentage = noise_percentage,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\ndataloaders = {'train':  train_loader, \n               'val': valid_loader_with_noise\n               }\ndataloaders_with_noise = {'train':  train_loader, \n               'val': valid_loader_with_noise\n               }\n\n\ntest_loader,test_size, _ = load_data(data_dir = data_dir,\n                           batch_size = 64,\n                           data_type = \"test\",\n                           noise_type = \"gaussian_noise\",\n                           noise_percentage = noise_percentage,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\n\n\ntest_loader_without_noise, _, _ = load_data(data_dir =data_dir,\n                           batch_size = 64,\n                           data_type = \"test\",\n                           noise_type = \"None\",\n                           noise_percentage = 0,                           \n                           transform = transform,                           \n                           data_percentage=data_percentage)\ndataset_sizes = {'train':  train_size, \n        'val': valid_size,\n        'test': test_size\n       }\n\n\ndataset_sizes","metadata":{"execution":{"iopub.status.busy":"2023-07-30T16:41:15.951911Z","iopub.execute_input":"2023-07-30T16:41:15.952258Z","iopub.status.idle":"2023-07-30T16:41:25.223103Z","shell.execute_reply.started":"2023-07-30T16:41:15.952230Z","shell.execute_reply":"2023-07-30T16:41:25.222161Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"path:  /kaggle/input/vegetableimages/vegetable_images/train\nneeded_length: 15000, expected_length_per_class: 1000\nlength of final dataset: 15000\npath:  /kaggle/input/vegetableimages/vegetable_images/validation\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\npath:  /kaggle/input/vegetableimages/vegetable_images/gaussian_noise/validation/10\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\npath:  /kaggle/input/vegetableimages/vegetable_images/gaussian_noise/test/10\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\npath:  /kaggle/input/vegetableimages/vegetable_images/test\nneeded_length: 3000, expected_length_per_class: 200\nlength of final dataset: 3000\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'train': 15000, 'val': 3000, 'test': 3000}"},"metadata":{}}]},{"cell_type":"code","source":"def load_resnet():\n    resnet = models.resnet101(weights=\"DEFAULT\")\n    \n    num_features = resnet.fc.in_features\n    num_classes = len(classes)  \n    resnet.fc = nn.Linear(num_features, num_classes)\n    for param in resnet.parameters():\n        param.requires_grad = True\n    \n    resnet.to(device)\n    return resnet\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-30T16:41:29.874738Z","iopub.execute_input":"2023-07-30T16:41:29.875200Z","iopub.status.idle":"2023-07-30T16:41:29.887244Z","shell.execute_reply.started":"2023-07-30T16:41:29.875159Z","shell.execute_reply":"2023-07-30T16:41:29.886349Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nlearning_rates = [0.005]\nmomentums = [0, 0.1]\nsteps = [3, 4]\ngammas = [0.1,  0.5]\n\ncolumns = ['model', 'num_epochs', 'learning_rate', 'momentum', 'step', 'gamma', 'accuracy', 'history']\nnum_epochs = 10\nht_results = pd.DataFrame(columns = columns)\nbest_valid_score = 0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nc = 0\nfor lr in learning_rates:\n    for m in momentums:\n        for s in steps:\n            for g in gammas: \n                c+=1\n                print(f\"\\n STARTING {c} ITERATION \\n\")\n                resnet_cr = load_resnet()\n                print(f\"Starting to test lr = {lr}, m = {m}, s = {s}, g = {g}\")\n                optimizer = optim.SGD(resnet_cr.parameters(), lr= lr, momentum = m)\n                step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n                resnet_cr, valid_score, history = train_model(resnet_cr, criterion, optimizer, \n                                                      step_lr_scheduler, num_epochs=num_epochs)\n                if best_valid_score < valid_score:\n                    best_valid_score = valid_score\n                    best_resnet = resnet_cr\n                ht_results.loc[len(ht_results.index)] = ['resnet', num_epochs, lr, m, s, g, valid_score, history]                \n                print(ht_results.loc[len(ht_results.index) - 1])\n                \n        \n        \n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-30T16:41:32.249610Z","iopub.execute_input":"2023-07-30T16:41:32.250661Z","iopub.status.idle":"2023-07-30T23:51:10.568910Z","shell.execute_reply.started":"2023-07-30T16:41:32.250611Z","shell.execute_reply":"2023-07-30T23:51:10.566814Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\n STARTING 1 ITERATION \n\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n100%|██████████| 171M/171M [00:00<00:00, 256MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Starting to test lr = 0.005, m = 0, s = 3, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 1.4596 Acc: 0.8011\n\n\nval Loss: 0.5640 Acc: 0.9600\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.2397 Acc: 0.9793\n\n\nval Loss: 0.1824 Acc: 0.9807\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0890 Acc: 0.9914\n\n\nval Loss: 0.1081 Acc: 0.9870\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0501 Acc: 0.9957\n\n\nval Loss: 0.0785 Acc: 0.9887\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0331 Acc: 0.9977\n\n\nval Loss: 0.0629 Acc: 0.9910\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0262 Acc: 0.9987\n\n\nval Loss: 0.0616 Acc: 0.9917\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0254 Acc: 0.9987\n\n\nval Loss: 0.0605 Acc: 0.9917\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0246 Acc: 0.9987\n\n\nval Loss: 0.0594 Acc: 0.9917\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0239 Acc: 0.9987\n\n\nval Loss: 0.0584 Acc: 0.9917\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0232 Acc: 0.9987\n\n\nval Loss: 0.0574 Acc: 0.9917\n\nTraining complete in 55m 47s\nBest val Acc: 0.991667\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             3\ngamma                                                          0.1\naccuracy                                                  0.991667\nhistory          [[0.8010666666666667, 0.9792666666666667, 0.99...\nName: 0, dtype: object\n\n STARTING 2 ITERATION \n\nStarting to test lr = 0.005, m = 0, s = 3, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 1.4793 Acc: 0.7904\n\n\nval Loss: 0.5649 Acc: 0.9583\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.2470 Acc: 0.9773\n\n\nval Loss: 0.1834 Acc: 0.9803\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0907 Acc: 0.9905\n\n\nval Loss: 0.1077 Acc: 0.9863\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0505 Acc: 0.9957\n\n\nval Loss: 0.0782 Acc: 0.9913\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0331 Acc: 0.9976\n\n\nval Loss: 0.0625 Acc: 0.9920\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0261 Acc: 0.9983\n\n\nval Loss: 0.0609 Acc: 0.9927\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0252 Acc: 0.9985\n\n\nval Loss: 0.0596 Acc: 0.9930\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0244 Acc: 0.9987\n\n\nval Loss: 0.0585 Acc: 0.9930\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0237 Acc: 0.9987\n\n\nval Loss: 0.0575 Acc: 0.9930\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0230 Acc: 0.9988\n\n\nval Loss: 0.0565 Acc: 0.9930\n\nTraining complete in 52m 25s\nBest val Acc: 0.993000\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             3\ngamma                                                          0.5\naccuracy                                                     0.993\nhistory          [[0.7904, 0.9772666666666667, 0.99053333333333...\nName: 1, dtype: object\n\n STARTING 3 ITERATION \n\nStarting to test lr = 0.005, m = 0, s = 4, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 1.4529 Acc: 0.8059\n\n\nval Loss: 0.5811 Acc: 0.9567\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.2495 Acc: 0.9792\n\n\nval Loss: 0.1985 Acc: 0.9793\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0915 Acc: 0.9914\n\n\nval Loss: 0.1189 Acc: 0.9853\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0509 Acc: 0.9960\n\n\nval Loss: 0.0871 Acc: 0.9893\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0333 Acc: 0.9976\n\n\nval Loss: 0.0704 Acc: 0.9917\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0262 Acc: 0.9987\n\n\nval Loss: 0.0684 Acc: 0.9917\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0253 Acc: 0.9987\n\n\nval Loss: 0.0670 Acc: 0.9917\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0246 Acc: 0.9987\n\n\nval Loss: 0.0658 Acc: 0.9917\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0238 Acc: 0.9987\n\n\nval Loss: 0.0647 Acc: 0.9917\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0231 Acc: 0.9988\n\n\nval Loss: 0.0637 Acc: 0.9917\n\nTraining complete in 53m 17s\nBest val Acc: 0.991667\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             4\ngamma                                                          0.1\naccuracy                                                  0.991667\nhistory          [[0.8059333333333334, 0.9792000000000001, 0.99...\nName: 2, dtype: object\n\n STARTING 4 ITERATION \n\nStarting to test lr = 0.005, m = 0, s = 4, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 1.4467 Acc: 0.8124\n\n\nval Loss: 0.5422 Acc: 0.9660\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.2401 Acc: 0.9791\n\n\nval Loss: 0.1747 Acc: 0.9847\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0896 Acc: 0.9907\n\n\nval Loss: 0.1036 Acc: 0.9883\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0506 Acc: 0.9951\n\n\nval Loss: 0.0749 Acc: 0.9903\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0335 Acc: 0.9977\n\n\nval Loss: 0.0597 Acc: 0.9923\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0265 Acc: 0.9986\n\n\nval Loss: 0.0582 Acc: 0.9923\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0256 Acc: 0.9986\n\n\nval Loss: 0.0570 Acc: 0.9923\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0249 Acc: 0.9987\n\n\nval Loss: 0.0560 Acc: 0.9923\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0241 Acc: 0.9988\n\n\nval Loss: 0.0550 Acc: 0.9927\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0234 Acc: 0.9988\n\n\nval Loss: 0.0540 Acc: 0.9930\n\nTraining complete in 53m 50s\nBest val Acc: 0.993000\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                         0\nstep                                                             4\ngamma                                                          0.5\naccuracy                                                     0.993\nhistory          [[0.8124, 0.9790666666666668, 0.99066666666666...\nName: 3, dtype: object\n\n STARTING 5 ITERATION \n\nStarting to test lr = 0.005, m = 0.1, s = 3, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 1.3285 Acc: 0.8277\n\n\nval Loss: 0.4619 Acc: 0.9637\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.1939 Acc: 0.9833\n\n\nval Loss: 0.1560 Acc: 0.9830\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0738 Acc: 0.9935\n\n\nval Loss: 0.0935 Acc: 0.9907\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0419 Acc: 0.9973\n\n\nval Loss: 0.0683 Acc: 0.9927\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0276 Acc: 0.9983\n\n\nval Loss: 0.0549 Acc: 0.9940\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0218 Acc: 0.9989\n\n\nval Loss: 0.0538 Acc: 0.9940\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0210 Acc: 0.9989\n\n\nval Loss: 0.0526 Acc: 0.9940\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0204 Acc: 0.9990\n\n\nval Loss: 0.0516 Acc: 0.9940\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0198 Acc: 0.9990\n\n\nval Loss: 0.0507 Acc: 0.9940\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0192 Acc: 0.9990\n\n\nval Loss: 0.0499 Acc: 0.9940\n\nTraining complete in 53m 26s\nBest val Acc: 0.994000\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             3\ngamma                                                          0.1\naccuracy                                                     0.994\nhistory          [[0.8276666666666667, 0.9833333333333334, 0.99...\nName: 4, dtype: object\n\n STARTING 6 ITERATION \n\nStarting to test lr = 0.005, m = 0.1, s = 3, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 1.3251 Acc: 0.8303\n\n\nval Loss: 0.4526 Acc: 0.9717\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.1892 Acc: 0.9828\n\n\nval Loss: 0.1557 Acc: 0.9853\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0713 Acc: 0.9935\n\n\nval Loss: 0.0960 Acc: 0.9900\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0403 Acc: 0.9972\n\n\nval Loss: 0.0718 Acc: 0.9913\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0267 Acc: 0.9986\n\n\nval Loss: 0.0586 Acc: 0.9923\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0211 Acc: 0.9991\n\n\nval Loss: 0.0571 Acc: 0.9927\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0205 Acc: 0.9991\n\n\nval Loss: 0.0559 Acc: 0.9927\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0199 Acc: 0.9991\n\n\nval Loss: 0.0550 Acc: 0.9927\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0193 Acc: 0.9991\n\n\nval Loss: 0.0541 Acc: 0.9927\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0187 Acc: 0.9991\n\n\nval Loss: 0.0533 Acc: 0.9930\n\nTraining complete in 53m 42s\nBest val Acc: 0.993000\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             3\ngamma                                                          0.5\naccuracy                                                     0.993\nhistory          [[0.8303333333333334, 0.9828, 0.99353333333333...\nName: 5, dtype: object\n\n STARTING 7 ITERATION \n\nStarting to test lr = 0.005, m = 0.1, s = 4, g = 0.1\nEpoch 1/10\n----------\n\ntrain Loss: 1.3515 Acc: 0.8206\n\n\nval Loss: 0.4382 Acc: 0.9693\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.1885 Acc: 0.9837\n\n\nval Loss: 0.1438 Acc: 0.9840\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0719 Acc: 0.9935\n\n\nval Loss: 0.0885 Acc: 0.9900\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0409 Acc: 0.9968\n\n\nval Loss: 0.0653 Acc: 0.9930\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0271 Acc: 0.9984\n\n\nval Loss: 0.0529 Acc: 0.9947\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0214 Acc: 0.9988\n\n\nval Loss: 0.0518 Acc: 0.9947\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0208 Acc: 0.9989\n\n\nval Loss: 0.0509 Acc: 0.9947\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0202 Acc: 0.9990\n\n\nval Loss: 0.0500 Acc: 0.9947\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0196 Acc: 0.9991\n\n\nval Loss: 0.0492 Acc: 0.9947\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0190 Acc: 0.9991\n\n\nval Loss: 0.0484 Acc: 0.9947\n\nTraining complete in 53m 43s\nBest val Acc: 0.994667\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             4\ngamma                                                          0.1\naccuracy                                                  0.994667\nhistory          [[0.8206, 0.9836666666666667, 0.99346666666666...\nName: 6, dtype: object\n\n STARTING 8 ITERATION \n\nStarting to test lr = 0.005, m = 0.1, s = 4, g = 0.5\nEpoch 1/10\n----------\n\ntrain Loss: 1.3716 Acc: 0.8129\n\n\nval Loss: 0.4799 Acc: 0.9670\n\nEpoch 2/10\n----------\n\ntrain Loss: 0.2057 Acc: 0.9815\n\n\nval Loss: 0.1556 Acc: 0.9843\n\nEpoch 3/10\n----------\n\ntrain Loss: 0.0765 Acc: 0.9924\n\n\nval Loss: 0.0944 Acc: 0.9890\n\nEpoch 4/10\n----------\n\ntrain Loss: 0.0429 Acc: 0.9970\n\n\nval Loss: 0.0701 Acc: 0.9920\n\nEpoch 5/10\n----------\n\ntrain Loss: 0.0282 Acc: 0.9984\n\n\nval Loss: 0.0568 Acc: 0.9930\n\nEpoch 6/10\n----------\n\ntrain Loss: 0.0222 Acc: 0.9988\n\n\nval Loss: 0.0555 Acc: 0.9930\n\nEpoch 7/10\n----------\n\ntrain Loss: 0.0215 Acc: 0.9988\n\n\nval Loss: 0.0545 Acc: 0.9937\n\nEpoch 8/10\n----------\n\ntrain Loss: 0.0209 Acc: 0.9989\n\n\nval Loss: 0.0536 Acc: 0.9937\n\nEpoch 9/10\n----------\n\ntrain Loss: 0.0202 Acc: 0.9989\n\n\nval Loss: 0.0528 Acc: 0.9937\n\nEpoch 10/10\n----------\n\ntrain Loss: 0.0197 Acc: 0.9990\n\n\nval Loss: 0.0520 Acc: 0.9937\n\nTraining complete in 53m 17s\nBest val Acc: 0.993667\nmodel                                                       resnet\nnum_epochs                                                      10\nlearning_rate                                                0.005\nmomentum                                                       0.1\nstep                                                             4\ngamma                                                          0.5\naccuracy                                                  0.993667\nhistory          [[0.8129333333333334, 0.9815333333333334, 0.99...\nName: 7, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"ht_results.to_csv('resnet_results.csv', index=False)\ntorch.save(best_resnet, \"best_resnet.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-07-31T00:00:15.041005Z","iopub.execute_input":"2023-07-31T00:00:15.041415Z","iopub.status.idle":"2023-07-31T00:00:15.376728Z","shell.execute_reply.started":"2023-07-31T00:00:15.041383Z","shell.execute_reply":"2023-07-31T00:00:15.375593Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working\n\nfrom IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T00:00:15.455020Z","iopub.execute_input":"2023-07-31T00:00:15.455335Z","iopub.status.idle":"2023-07-31T00:00:35.880682Z","shell.execute_reply.started":"2023-07-31T00:00:15.455308Z","shell.execute_reply":"2023-07-31T00:00:35.879013Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"updating: kaggle/working/ (stored 0%)\nupdating: kaggle/working/.virtual_documents/ (stored 0%)\nupdating: kaggle/working/resnet_results.csv (deflated 84%)\nupdating: kaggle/working/best_vgg16.pth (deflated 7%)\n  adding: kaggle/working/best_resnet.pth (deflated 7%)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
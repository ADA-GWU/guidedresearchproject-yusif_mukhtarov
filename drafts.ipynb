{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, classes):\n",
    "\n",
    "    results = pd.DataFrame([[]], columns = ['Class', 'Accuracy', 'Recall', 'Precision', 'F_score'])\n",
    "\n",
    "    model.eval()\n",
    "    y_pred1 = torch.tensor([])\n",
    "    y_target1 = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for _ in range(len(classes))]\n",
    "        n_class_samples = [0 for _ in range(len(classes))]\n",
    "        n_class_true_positives = [0 for _ in range(len(classes))]\n",
    "        n_class_preds = [0 for _ in range(len(classes))]\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "             \n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            y_pred1 = torch.cat((predicted, y_pred1), dim=0)\n",
    "            y_target1 = torch.cat((labels, y_target1), dim=0)\n",
    "            \n",
    "            for i in range(len(images)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if label == pred:\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "                n_class_preds[pred] +=1                \n",
    "                n_class_true_positives[pred] += int(pred == label)\n",
    "                \n",
    "                \n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        recall_arr = []\n",
    "        precision_arr = []\n",
    "        f_score_arr = []\n",
    "\n",
    "        for i in range(len(classes)):\n",
    "            precision = n_class_true_positives[i] / n_class_preds[i]\n",
    "            recall = n_class_true_positives[i] /n_class_samples[i]\n",
    "            f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            recall_arr.append(round(recall, 4))\n",
    "            precision_arr.append(round(precision, 4))\n",
    "            f_score_arr.append(round(f_score, 4))\n",
    "\n",
    "            results.loc[len(results.index)] = [classes[i], n_class_correct[i] / n_class_samples[i], recall, precision, f_score] \n",
    "            \n",
    "            print(f'Class: {classes[i]}')\n",
    "            print(f'Accuracy: {100.0 * n_class_correct[i] / n_class_samples[i]} %')\n",
    "            print('---')\n",
    "        mcr = MulticlassRecall(num_classes=len(classes), average=None)\n",
    "        mcp = MulticlassPrecision(num_classes=len(classes), average=None)\n",
    "\n",
    "        print(\"\\n Recall using torchmet\", mcr(y_pred1, y_target1))\n",
    "        print(\"Recall\", recall_arr)\n",
    "\n",
    "        print(\"\\n Precision:\", mcp(y_pred1, y_target1))\n",
    "        print(\"Precision:\", precision_arr)\n",
    "        print(f_score_arr)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from dataloading import load_data\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  ../data/vegetable_images/train\n",
      "needed_length: 1500, expected_length_per_class: 100\n",
      "length of final dataset: 1500\n",
      "path:  ../data/vegetable_images/validation\n",
      "needed_length: 300, expected_length_per_class: 20\n",
      "length of final dataset: 300\n",
      "path:  ../data/vegetable_images/gaussian_noise/validation/10\n",
      "needed_length: 300, expected_length_per_class: 20\n",
      "length of final dataset: 300\n",
      "path:  ../data/vegetable_images/gaussian_noise/test/10\n",
      "needed_length: 300, expected_length_per_class: 20\n",
      "length of final dataset: 300\n",
      "path:  ../data/vegetable_images/test\n",
      "needed_length: 300, expected_length_per_class: 20\n",
      "length of final dataset: 300\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4680, 0.4647, 0.3441], std=[0.2322, 0.2272, 0.2394]) \n",
    "])   \n",
    "\n",
    "noise_type = \"gaussian_noise\"\n",
    "noise_percentage = 10\n",
    "data_percentage = 10\n",
    "\n",
    "\n",
    "train_loader, _, classes = load_data(data_dir = '../data/vegetable_images',\n",
    "                           batch_size = 64,\n",
    "                           data_type = \"train\",\n",
    "                           noise_type = \"None\",\n",
    "                           noise_percentage = 0,                           \n",
    "                           transform = transform,                           \n",
    "                           data_percentage=data_percentage)\n",
    "\n",
    "valid_loader, _, _ = load_data(data_dir = '../data/vegetable_images',\n",
    "                           batch_size = 64,\n",
    "                           data_type = \"validation\",\n",
    "                           noise_type = \"None\",\n",
    "                           noise_percentage = 0,                           \n",
    "                           transform = transform,                           \n",
    "                           data_percentage=data_percentage)\n",
    "\n",
    "valid_loader_with_noise, _, _ = load_data(data_dir = '../data/vegetable_images',\n",
    "                           batch_size = 64,\n",
    "                           data_type = \"validation\",\n",
    "                           noise_type = noise_type,\n",
    "                           noise_percentage = noise_percentage,                           \n",
    "                           transform = transform,                           \n",
    "                           data_percentage=data_percentage)\n",
    "dataloaders = {'train':  train_loader, \n",
    "               'val': valid_loader\n",
    "               }\n",
    "dataloaders_with_noise = {'train':  train_loader, \n",
    "               'val': valid_loader_with_noise\n",
    "               }\n",
    "\n",
    "\n",
    "test_loader, _, _ = load_data(data_dir = '../data/vegetable_images',\n",
    "                           batch_size = 64,\n",
    "                           data_type = \"test\",\n",
    "                           noise_type = \"gaussian_noise\",\n",
    "                           noise_percentage = noise_percentage,                           \n",
    "                           transform = transform,                           \n",
    "                           data_percentage=data_percentage)\n",
    "\n",
    "\n",
    "test_loader_without_noise, _, _ = load_data(data_dir = '../data/vegetable_images',\n",
    "                           batch_size = 64,\n",
    "                           data_type = \"test\",\n",
    "                           noise_type = \"None\",\n",
    "                           noise_percentage = 0,                           \n",
    "                           transform = transform,                           \n",
    "                           data_percentage=data_percentage)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "3000\n",
      "3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bean',\n",
       " 'Bitter_Gourd',\n",
       " 'Bottle_Gourd',\n",
       " 'Brinjal',\n",
       " 'Broccoli',\n",
       " 'Cabbage',\n",
       " 'Capsicum',\n",
       " 'Carrot',\n",
       " 'Cauliflower',\n",
       " 'Cucumber',\n",
       " 'Papaya',\n",
       " 'Potato',\n",
       " 'Pumpkin',\n",
       " 'Radish',\n",
       " 'Tomato']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataloaders['train'].dataset))\n",
    "print(len(dataloaders['val'].dataset))\n",
    "\n",
    "dataset_sizes = {'train' : len(dataloaders['train'].dataset), 'val': len(dataloaders['val'].dataset), 'test': len(test_loader.dataset)}\n",
    "print(len(test_loader.dataset))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._modules['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=4096, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_features = model._modules['classifier'][-1].in_features\n",
    "out_features = len(classes)\n",
    "model._modules['classifier'][-1] = nn.Linear(in_features, out_features, bias=True)\n",
    "print(model._modules['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader_without_noise.dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN IMAGES WITHOUT NOISE BEFORE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 7.666666666666667 %\n",
      "Accuracy of Bean: 10.5 %\n",
      "Accuracy of Bitter_Gourd: 3.0 %\n",
      "Accuracy of Bottle_Gourd: 22.0 %\n",
      "Accuracy of Brinjal: 2.0 %\n",
      "Accuracy of Broccoli: 12.5 %\n",
      "Accuracy of Cabbage: 5.0 %\n",
      "Accuracy of Capsicum: 1.0 %\n",
      "Accuracy of Carrot: 13.5 %\n",
      "Accuracy of Cauliflower: 2.0 %\n",
      "Accuracy of Cucumber: 1.5 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader_without_noise:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH 10 BEFORE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 6.733333333333333 %\n",
      "Accuracy of Bean: 13.0 %\n",
      "Accuracy of Bitter_Gourd: 1.5 %\n",
      "Accuracy of Bottle_Gourd: 18.0 %\n",
      "Accuracy of Brinjal: 3.0 %\n",
      "Accuracy of Broccoli: 14.5 %\n",
      "Accuracy of Cabbage: 5.5 %\n",
      "Accuracy of Capsicum: 1.0 %\n",
      "Accuracy of Carrot: 12.0 %\n",
      "Accuracy of Cauliflower: 0.5 %\n",
      "Accuracy of Cucumber: 0.5 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "       \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs =  torch.tensor(inputs).to(device)\n",
    "                labels = torch.tensor(labels).to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "    \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_8688\\2272575281.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs =  torch.tensor(inputs).to(device)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_8688\\2272575281.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2029 Acc: 0.0407\n",
      "val Loss: 0.1203 Acc: 0.0800\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.0939 Acc: 0.0796\n",
      "val Loss: 0.0571 Acc: 0.0887\n",
      "\n",
      "Training complete in 1m 26s\n",
      "Best val Acc: 0.088667\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = torch.load('../models/alexnet_without_noise.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 99.66666666666667 %\n",
      "Accuracy of Bean: 100.0 %\n",
      "Accuracy of Bitter_Gourd: 99.0 %\n",
      "Accuracy of Bottle_Gourd: 100.0 %\n",
      "Accuracy of Brinjal: 99.5 %\n",
      "Accuracy of Broccoli: 99.0 %\n",
      "Accuracy of Cabbage: 99.5 %\n",
      "Accuracy of Capsicum: 99.5 %\n",
      "Accuracy of Carrot: 100.0 %\n",
      "Accuracy of Cauliflower: 100.0 %\n",
      "Accuracy of Cucumber: 99.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader_without_noise:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 15.533333333333333 %\n",
      "Accuracy of Bean: 0.0 %\n",
      "Accuracy of Bitter_Gourd: 95.0 %\n",
      "Accuracy of Bottle_Gourd: 9.5 %\n",
      "Accuracy of Brinjal: 0.0 %\n",
      "Accuracy of Broccoli: 27.5 %\n",
      "Accuracy of Cabbage: 0.0 %\n",
      "Accuracy of Capsicum: 0.0 %\n",
      "Accuracy of Carrot: 0.5 %\n",
      "Accuracy of Cauliflower: 0.5 %\n",
      "Accuracy of Cucumber: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign-lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
